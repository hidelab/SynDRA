{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Methods**\n",
    "\n",
    "## **Data Sources**\n",
    "\n",
    "To construct a unified and comprehensive drug synonym database, we integrated four independent data sources:\n",
    "\n",
    "1. **KatDB Synonyms**\n",
    "   - **Source**: Developed by Kat Koler  \n",
    "   - **File**: `L1000_BRD_name_translated_drug_list.csv`  \n",
    "   - **Description**: This dataset includes multiple synonyms per BROAD compound identifier, designed to improve drug name recognition in L1000 experiments.  \n",
    "   - **Example**: The BROAD_drug_ID `BRD-K52256627` includes synonyms ranging from “chlorhexidine” to complex chemical names.\n",
    "\n",
    "2. **Therapeutic Targets Database (TTD)**\n",
    "   - **URL**: [TTD Full Download](https://idrblab.org/ttd/)  \n",
    "   - **File**: `P1-04-Drug_synonyms.txt`  \n",
    "   - **Description**: Drug synonym lists associated with therapeutic targets.  \n",
    "   - **Example**: Drug ID `D00AAN` includes synonyms like “d00aan” and various chemical descriptors.\n",
    "\n",
    "3. **PRISM Drug Synonyms**\n",
    "   - **URL**: [PRISM GitHub Repository](https://github.com/broadinstitute/prism_repurposing)  \n",
    "   - **File**: `PRISM_drug_synonyms.csv`  \n",
    "   - **Description**: From PRISM repurposing screen, supports MOA enrichment.  \n",
    "   - **Example**: `PubChem_CID 11314340` has synonyms such as “a-674563”.\n",
    "\n",
    "4. **LINCS 2020 Compound Metadata**\n",
    "   - **File**: `compoundinfo_beta.txt`  \n",
    "   - **URL**: [Clue.io Data Dashboard](https://clue.io/releases/data-dashboard)  \n",
    "   - **Path**: `/data/work/tolga/Signature_processing_and_drug_prioritisation/analysis/synonym_database/input/LINCS2020/`  \n",
    "   - **Description**: Contains compound identifiers used in the L1000 assay from Clue.io.\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Characteristics**\n",
    "\n",
    "- **Initial Entry Counts**:  \n",
    "  - `katdb_df`: 13,176  \n",
    "  - `ttd_df`: 299,047  \n",
    "  - `prism_df`: 112,784\n",
    "\n",
    "- **Initial Unique Synonym Counts**:  \n",
    "  - BROAD: 13,175  \n",
    "  - TTD: 299,046  \n",
    "  - PubChem: 112,675\n",
    "\n",
    "- **Unique Identifier Counts**:  \n",
    "  - BROAD_drug_IDs: 5,539  \n",
    "  - TTD_drug_IDs: 30,713  \n",
    "  - PubChem_CIDs: 1,351\n",
    "\n",
    "- **LINCS2020 Coverage**:  \n",
    "  - Unique BROAD_drug_IDs: 33,613  \n",
    "  - Unique synonyms: 34,234\n",
    "\n",
    "- **Combined LINCS2020 + KatDB**:  \n",
    "  - Unique BROAD_drug_IDs: 33,858  \n",
    "  - Unique synonyms: 45,617\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Preparation**\n",
    "\n",
    "Normalization steps applied:\n",
    "\n",
    "- Converted all synonyms to lowercase  \n",
    "- Split multi-synonym strings into separate rows  \n",
    "- Stripped whitespace and formatting artifacts  \n",
    "\n",
    "This allowed consistent matching across datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Merging Strategy**\n",
    "\n",
    "1. **Synonym Explosion**  \n",
    "   One synonym per row using `.explode()`.\n",
    "\n",
    "2. **Outer Join on Synonyms**  \n",
    "   To retain as many matches as possible.\n",
    "\n",
    "3. **ID Propagation**  \n",
    "   Shared synonyms helped propagate IDs across datasets using forward/backward fill.\n",
    "\n",
    "4. **Grouping & Aggregation**  \n",
    "   Aggregated synonyms based on unique sets of IDs.\n",
    "\n",
    "5. **Filter Rows**  \n",
    "   Dropped rows with missing `BROAD_drug_ID`, as the focus was on LINCS platform.\n",
    "\n",
    "---\n",
    "\n",
    "# **Results**\n",
    "\n",
    "## **Merged Dataset Overview**\n",
    "\n",
    "- **Final DataFrame Shape**: (193,221 rows × 4 columns)  \n",
    "- **Final Unique Synonym Count**: 193,113  \n",
    "\n",
    "### **Unique Identifier Counts**\n",
    "\n",
    "- BROAD_drug_IDs: 33,858  \n",
    "- TTD_drug_IDs: 2,775  \n",
    "- PubChem_CIDs: 950\n",
    "\n",
    "### **Missing Values (NaNs)**\n",
    "\n",
    "- `BROAD_drug_ID`: 0  \n",
    "- `synonyms`: 0  \n",
    "- `TTD_drug_ID`: 45,737  \n",
    "- `PubChem_CID`: 88,237\n",
    "\n",
    "### **Data Types**\n",
    "\n",
    "- BROAD_drug_ID: object  \n",
    "- synonyms: object  \n",
    "- TTD_drug_ID: object  \n",
    "- PubChem_CID: float64\n",
    "\n",
    "- **Duplicate Rows**: 0\n",
    "\n",
    "---\n",
    "\n",
    "## **Sample Entries**\n",
    "\n",
    "### First Rows\n",
    "\n",
    "| BROAD_drug_ID | Synonym                     | TTD_drug_ID | PubChem_CID |\n",
    "| ------------- | --------------------------- | ----------- | ------------|\n",
    "| BRD-K52256627 | chlorhexidine               | D0V4GY      | 9552079     |\n",
    "| BRD-K52256627 | chlorhexidine, combinations | D0V4GY      | 9552079     |\n",
    "| BRD-K52256627 | 1,1'-hexamethylenebis[...]  | D0V4GY      | 9552079     |\n",
    "\n",
    "### Last Rows\n",
    "\n",
    "| BROAD_drug_ID | Synonym                    | TTD_drug_ID | PubChem_CID |\n",
    "| ------------- | -------------------------- | ----------- | ------------|\n",
    "| BRD-K63068307 | 2-(difluoromethyl)-1-[...] | D0O1LD      | 11647372    |\n",
    "| BRD-K63068307 | zs4                        | D0O1LD      | 11647372    |\n",
    "\n",
    "---\n",
    "\n",
    "## **Match Statistics**\n",
    "\n",
    "| Category                         | Initial Entries | Final Entries |\n",
    "| -------------------------------- | --------------- | ------------- |\n",
    "| BROAD_drug_ID                    | 45,617          | 33,858        |\n",
    "| TTD_drug_ID                      | 299,047         | 2,775         |\n",
    "| PubChem_CID                      | 112,784         | 950           |\n",
    "| **Total Merged Rows**            | —               | 435,530       |\n",
    "| **Final Unique Synonym Groups**  | —               | 193,221       |\n",
    "| **Matched Identifier Instances** | —               | 1,145         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "yMcuQN6vt0Ve"
   },
   "outputs": [],
   "source": [
    "# prompt: get tsv and csv files from input folder KatDB/  PRISM_drug_synonims/  Therapeutic_Targets_Database_Synonims/ upload ['P1-04-Drug_synonyms.tsv']\n",
    "# ['L1000_BRD_name_translated_drug_list.csv', 'PRISM_drug_synonyms.csv'] as ttd_df, prism_df and katdb_df\n",
    "\n",
    "import pandas as pd\n",
    "katdb_df = pd.read_csv('../input/KatDB/L1000_BRD_name_translated_drug_list.csv')\n",
    "\n",
    "prism_df = pd.read_csv('../input/PRISM_drug_synonims/PRISM_drug_synonyms.csv')\n",
    "ttd_df = pd.read_csv(\"../input/Therapeutic_Targets_Database_Synonims/P1-04-Drug_synonyms.tsv\", sep='\\t')\n",
    "genesetMetadata = pd.read_csv(\n",
    "    \"/data/work/tolga/Signature_processing_and_drug_prioritisation/analysis/synonym_database/input/LINCS2020/compoundinfo_beta.txt\",\n",
    "    sep=\"\\t\",  # Tab-delimited file\n",
    "    engine='c'  # Default engine should work fine for tab-delimited files\n",
    ")\n",
    "\n",
    "genesetMetadata2 = genesetMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique BROAD_drug_IDs in LINCS2020: 33613\n",
      "Number of unique synonyms in LINCS2020: 34234\n",
      "Number of NaN values in synonyms column: 0\n"
     ]
    }
   ],
   "source": [
    "genesetMetadata = genesetMetadata.rename(columns={'pert_id': 'BROAD_drug_ID'})# fill NaN values in cmap_name and alias_list with empty strings\n",
    "\n",
    "# Keep only the two required columns\n",
    "genesetMetadata = genesetMetadata[['BROAD_drug_ID', 'compound_aliases']]\n",
    "\n",
    "# Drop rows where alias_list is NaN\n",
    "genesetMetadata = genesetMetadata.dropna(subset=['compound_aliases'])\n",
    "\n",
    "genesetMetadata = genesetMetadata.explode('compound_aliases')\n",
    "# Convert alias_list to lowercase and strip whitespace\n",
    "genesetMetadata['compound_aliases'] = genesetMetadata['compound_aliases'].str.lower().str.strip()\n",
    "# Remove duplicates in alias_list\n",
    "genesetMetadata = genesetMetadata.drop_duplicates(subset=['compound_aliases'])\n",
    "# Rename alias_list to synonyms\n",
    "genesetMetadata = genesetMetadata.rename(columns={'compound_aliases': 'synonyms'})\n",
    "# Reset index after dropping duplicates\n",
    "genesetMetadata.reset_index(drop=True, inplace=True)\n",
    "# Display the first 20 rows of the updated genesetMetadata DataFrame\n",
    "\n",
    "\n",
    "genesetMetadata2.head(1)\n",
    "#merge cmap_name and alias_list columns in genesetMetadata to synonyms\n",
    "genesetMetadata2['synonyms'] = genesetMetadata2['cmap_name']\n",
    "# #append alias_list to synonyms, if alias_list is not NaN\n",
    "# genesetMetadata2['synonyms'] = genesetMetadata2.apply(\n",
    "#     lambda row: row['synonyms'] + '|' + row['alias_list'] if pd.notna(row['alias_list']) else row['synonyms'], axis=1\n",
    "# )\n",
    "#rename pert_id column in genesetMetadata to BROAD_drug_ID \n",
    "genesetMetadata2 = genesetMetadata2.rename(columns={'pert_id': 'BROAD_drug_ID'})# fill NaN values in cmap_name and alias_list with empty strings\n",
    "\n",
    "#only include BROAD_drug_ID, synonyms columns in genesetMetadata\n",
    "genesetMetadata2 = genesetMetadata2[['BROAD_drug_ID', 'synonyms']]\n",
    "# drop rows where synonyms is NaN\n",
    "genesetMetadata2 = genesetMetadata2.dropna(subset=['synonyms'])\n",
    "\n",
    "genesetMetadata2\n",
    "\n",
    "lincs_df = pd.concat([genesetMetadata2, genesetMetadata], ignore_index=True)\n",
    "# Remove duplicates based on the 'synonyms' column\n",
    "lincs_df = lincs_df.drop_duplicates(subset=['synonyms'])\n",
    "# unique Broad_drug_IDs in lincs_df\n",
    "unique_broad_drug_ids = lincs_df['BROAD_drug_ID'].unique()\n",
    "print(f\"Number of unique BROAD_drug_IDs in LINCS2020: {len(unique_broad_drug_ids)}\")\n",
    "#unique synonyms in lincs_df\n",
    "unique_synonyms = lincs_df['synonyms'].unique()\n",
    "print(f\"Number of unique synonyms in LINCS2020: {len(unique_synonyms)}\")\n",
    "#number if na values in synonyms column\n",
    "na_synonyms_count = lincs_df['synonyms'].isna().sum()\n",
    "print(f\"Number of NaN values in synonyms column: {na_synonyms_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "lqMovVYElf5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique BROAD_drug_IDs in KatDB: 5539\n",
      "Number of unique synonyms in KatDB: 13175\n"
     ]
    }
   ],
   "source": [
    "# prompt: katdb_df str.lower(target_name) and drop target_name duplicates, change target_name column name to synonyms, drop input_type column, change input_name column name to BROAD_drug_ID\n",
    "\n",
    "katdb_df['target_name'] = katdb_df['target_name'].str.lower()\n",
    "katdb_df.drop_duplicates(subset=['target_name'], inplace=True)\n",
    "katdb_df.rename(columns={'target_name': 'synonyms', 'input_name': 'BROAD_drug_ID'}, inplace=True)\n",
    "katdb_df.drop(columns=['input_type'], inplace=True)\n",
    "\n",
    "katdb_df.drop(columns=['target_type'], inplace=True)\n",
    "\n",
    "katdb_df.drop(columns=['kat_id'], inplace=True)\n",
    "\n",
    "#drop rows where synonyms is NaN in katdb_df\n",
    "katdb_df = katdb_df.dropna(subset=['synonyms'])\n",
    "#number of unique broad ids katdb_df\n",
    "unique_broad_ids_katdb = katdb_df['BROAD_drug_ID'].unique()\n",
    "print(f\"Number of unique BROAD_drug_IDs in KatDB: {len(unique_broad_ids_katdb)}\")\n",
    "#number of unique synonyms katdb_df\n",
    "unique_synonyms_katdb = katdb_df['synonyms'].unique()\n",
    "print(f\"Number of unique synonyms in KatDB: {len(unique_synonyms_katdb)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "IzDIwT8NQ5gQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique TTD_drug_ID in TTD: 30713\n",
      "Number of unique synonyms in TTD: 299047\n"
     ]
    }
   ],
   "source": [
    "# prompt: ttd_df str.lower(Synonyms_column) and drop Synonyms_column duplicates\n",
    "\n",
    "ttd_df['Synonyms_column'] = ttd_df['Synonyms_column'].str.lower()\n",
    "ttd_df = ttd_df.drop_duplicates(subset=['Synonyms_column'])\n",
    "ttd_df = ttd_df.rename(columns={'Synonyms_column': 'synonyms'})\n",
    "ttd_df.drop(columns=['Abbreviation'], inplace=True)\n",
    "\n",
    "# number of unique broad ids ttd_df\n",
    "unique_broad_ids_ttd = ttd_df['TTD_drug_ID'].unique()\n",
    "print(f\"Number of unique TTD_drug_ID in TTD: {len(unique_broad_ids_ttd)}\")\n",
    "# number of unique synonyms ttd_df\n",
    "unique_synonyms_ttd = ttd_df['synonyms'].unique()\n",
    "print(f\"Number of unique synonyms in TTD: {len(unique_synonyms_ttd)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1722523778865,
     "user": {
      "displayName": "Tolga Çorbacı",
      "userId": "09183873162992117182"
     },
     "user_tz": 240
    },
    "id": "WdyoFE6oRY4d",
    "outputId": "96292d44-11f7-43fe-b251-2c1e86c38122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique PubChem_CID in PRISM: 1351\n",
      "Number of unique synonyms in PRISM: 112675\n"
     ]
    }
   ],
   "source": [
    "# Function to split, lower case, and remove duplicates\n",
    "def process_synonyms(synonyms):\n",
    "    unique_synonyms = list(dict.fromkeys([syn.strip().lower() for syn in synonyms.split('|')]))\n",
    "    return unique_synonyms\n",
    "\n",
    "# Apply the function to the PubChem_synonyms column and explode into separate rows\n",
    "prism_df['Processed_synonyms'] = prism_df['PubChem_synonyms'].apply(process_synonyms)\n",
    "prism_exploded = prism_df.explode('Processed_synonyms')\n",
    "\n",
    "# Rename the exploded column to PubChem_synonym\n",
    "prism_exploded = prism_exploded.rename(columns={'Processed_synonyms': 'PubChem_synonym'})\n",
    "\n",
    "# Drop the original PubChem_synonyms column if desired\n",
    "prism_df = prism_exploded.drop(columns=['PubChem_synonyms'])\n",
    "prism_df = prism_df.rename(columns={'PRISM_drug_name': 'PRISM_drug_ID'})\n",
    "\n",
    "prism_df = prism_df.rename(columns={'PubChem_synonym': 'synonyms'})\n",
    "\n",
    "# Display the final dataframe\n",
    "prism_df.drop(columns=['PRISM_drug_ID'], inplace=True)\n",
    "\n",
    "#number of unique PRISM_drug_ID in prism_df\n",
    "unique_prism_drug_ids = prism_df['PubChem_CID'].unique()\n",
    "print(f\"Number of unique PubChem_CID in PRISM: {len(unique_prism_drug_ids)}\")\n",
    "\n",
    "#number of unique PubChem_synonyms in prism_df\n",
    "unique_pubchem_synonyms = prism_df['synonyms'].unique()\n",
    "print(f\"Number of unique synonyms in PRISM: {len(unique_pubchem_synonyms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1722523795082,
     "user": {
      "displayName": "Tolga Çorbacı",
      "userId": "09183873162992117182"
     },
     "user_tz": 240
    },
    "id": "WUH2iHD9Ywig",
    "outputId": "09e9708e-874d-45cf-aa2a-9eddaecc2115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "katdb_df head:\n",
      "   BROAD_drug_ID       synonyms\n",
      "0  BRD-K52256627  chlorhexidine\n",
      "lincs_df head:\n",
      "   BROAD_drug_ID    synonyms\n",
      "0  BRD-A08715367  L-theanine\n",
      "\n",
      "ttd_df head:\n",
      "  TTD_drug_ID synonyms\n",
      "0      D00AAN   d00aan\n",
      "\n",
      "prism_df head:\n",
      "   PubChem_CID  synonyms\n",
      "0     11314340  a-674563\n"
     ]
    }
   ],
   "source": [
    "# prompt: print the the heads of katdb_df, ttd_df and prism_df, include their names\n",
    "\n",
    "print(\"katdb_df head:\")\n",
    "print(katdb_df.head(1))\n",
    "print(\"lincs_df head:\")\n",
    "print(lincs_df.head(1))\n",
    "print(\"\\nttd_df head:\")\n",
    "print(ttd_df.head(1))\n",
    "print(\"\\nprism_df head:\")\n",
    "print(prism_df.head(1))\n",
    "# Replace \"nan\" strings with np.nan in ID columns of each dataframe\n",
    "katdb_df['BROAD_drug_ID'].replace(\"nan\", np.nan, inplace=True)\n",
    "lincs_df['BROAD_drug_ID'].replace(\"nan\", np.nan, inplace=True)\n",
    "ttd_df['TTD_drug_ID'].replace(\"nan\", np.nan, inplace=True)\n",
    "prism_df['PubChem_CID'].replace(\"nan\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique BROAD_drug_IDs in combined LINCS2020 and KatDB: 33858\n",
      "Number of unique synonyms in combined LINCS2020 and KatDB: 45617\n"
     ]
    }
   ],
   "source": [
    "# concatenate katdb_df and lincs_df\n",
    "combined_lincs_df = pd.concat([katdb_df, lincs_df], ignore_index=True)\n",
    "#drop duplicates based on synonyms column\n",
    "combined_lincs_df = combined_lincs_df.drop_duplicates(subset=['synonyms'])\n",
    "#number of unique BROAD_drug_IDs in combined_lincs_df\n",
    "unique_broad_drug_ids_combined = combined_lincs_df['BROAD_drug_ID'].unique()\n",
    "print(f\"Number of unique BROAD_drug_IDs in combined LINCS2020 and KatDB: {len(unique_broad_drug_ids_combined)}\")\n",
    "#number of unique synonyms in combined_lincs_df\n",
    "unique_synonyms_combined = combined_lincs_df['synonyms'].unique()\n",
    "print(f\"Number of unique synonyms in combined LINCS2020 and KatDB: {len(unique_synonyms_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1722523851307,
     "user": {
      "displayName": "Tolga Çorbacı",
      "userId": "09183873162992117182"
     },
     "user_tz": 240
    },
    "id": "zrGupErTBnUO",
    "outputId": "167e5528-68be-49c6-d3b9-50ae698f4862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Report:\n",
      "--------------------\n",
      "\n",
      "Initial Shapes:\n",
      "BROAD_drug_ID: (45617, 2)\n",
      "TTD_drug_ID: (299047, 2)\n",
      "PubChem_CID: (112784, 2)\n",
      "\n",
      "Initial Unique Counts:\n",
      "BROAD_drug_ID: 45617\n",
      "TTD_drug_ID: 299046\n",
      "PubChem_CID: 112675\n",
      "\n",
      "Final Shape (Merged): (435530, 4)\n",
      "Final Unique Count (Merged): 435420\n",
      "\n",
      "Matched Instances: 1145\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "dfs = [combined_lincs_df, ttd_df, prism_df]\n",
    "# merged_df = reduce(lambda left, right: pd.merge(left, right, on='synonyms', how='outer'), dfs)\n",
    "\n",
    "# Calculate shapes and unique occurrences before merging\n",
    "initial_shapes = {df.columns[0]: df.shape for df in dfs}\n",
    "initial_unique_counts = {df.columns[0]: df['synonyms'].nunique() for df in dfs}\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on='synonyms', how='outer'), dfs)\n",
    "\n",
    "# Calculate shape and unique occurrences after merging\n",
    "final_shape = merged_df.shape\n",
    "final_unique_count = merged_df['synonyms'].nunique()\n",
    "\n",
    "# Generate the report\n",
    "print(\"Match Report:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"\\nInitial Shapes:\")\n",
    "for name, shape in initial_shapes.items():\n",
    "  print(f\"{name}: {shape}\")\n",
    "\n",
    "print(\"\\nInitial Unique Counts:\")\n",
    "for name, count in initial_unique_counts.items():\n",
    "  print(f\"{name}: {count}\")\n",
    "\n",
    "print(\"\\nFinal Shape (Merged):\", final_shape)\n",
    "print(\"Final Unique Count (Merged):\", final_unique_count)\n",
    "\n",
    "# Calculate matched instances\n",
    "matched_instances = merged_df.dropna()\n",
    "print(\"\\nMatched Instances:\", matched_instances.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1722523963291,
     "user": {
      "displayName": "Tolga Çorbacı",
      "userId": "09183873162992117182"
     },
     "user_tz": 240
    },
    "id": "2Rg7uKeQGjF0",
    "outputId": "c82aaa3f-9f73-4f23-986d-5ef496a795f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique BROAD_drug_IDs: 33858\n",
      "Number of unique TTD_drug_IDs: 30713\n",
      "Number of unique PubChem_CIDs: 1351\n"
     ]
    }
   ],
   "source": [
    "# prompt: # Get the number of  unique values for each ID column in each separate DataFrame\n",
    "unique_combined_lincs_df_ids = combined_lincs_df['BROAD_drug_ID'].unique()\n",
    "unique_ttd_ids = ttd_df['TTD_drug_ID'].unique()\n",
    "unique_prism_ids = prism_df['PubChem_CID'].unique()\n",
    "\n",
    "# Get the number of unique values for each ID column in each separate DataFrame\n",
    "num_unique_combined_lincs_df_ids = len(unique_combined_lincs_df_ids)\n",
    "num_unique_ttd_ids = len(unique_ttd_ids)\n",
    "num_unique_prism_ids = len(unique_prism_ids)\n",
    "\n",
    "print(\"Number of unique BROAD_drug_IDs:\", num_unique_combined_lincs_df_ids)\n",
    "print(\"Number of unique TTD_drug_IDs:\", num_unique_ttd_ids)\n",
    "print(\"Number of unique PubChem_CIDs:\", num_unique_prism_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged df astype str\n",
    "merged_df = merged_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no 'nan' strings in the merged DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# check if there are any NaN values in the merged_df as \"nan\" strings in the ID columns\n",
    "import numpy as np\n",
    "nan_in_merged_df = merged_df.isin(['nan']).any().any()\n",
    "if nan_in_merged_df:\n",
    "    print(\"There are 'nan' strings in the merged DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no 'nan' strings in the merged DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 'nan' strings in the merged DataFrame, so we will replace them with np.nan\n",
    "merged_df.replace(\"nan\", np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [PubChem_CID, TTD_drug_ID, BROAD_drug_ID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def clean_fake_nans(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: np.nan if isinstance(x, str) and x.strip().lower() in ['nan', 'missing'] else x\n",
    "        )\n",
    "    return df\n",
    "\n",
    "merged_df = clean_fake_nans(merged_df, ['PubChem_CID', 'TTD_drug_ID', 'BROAD_drug_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['PubChem_CID'] = pd.to_numeric(merged_df['PubChem_CID'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Fill NaNs in each column using grouped non-null values based on shared identifiers\n",
    "# def groupwise_fill(df, group_keys, fill_columns):\n",
    "#     for col in fill_columns:\n",
    "#         for key in group_keys:\n",
    "#             df[col] = df.groupby(key)[col].transform(lambda x: x.ffill().bfill() if x.notna().any() else x)\n",
    "#     return df\n",
    "\n",
    "# # Example usage\n",
    "\n",
    "\n",
    "# #synonym_df = groupwise_fill(merged_df, group_keys, fill_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonym_df = pd.read_csv('/data/work/tolga/Signature_processing_and_drug_prioritisation/analysis/synonym_database/output/merged_40K_drug_synonyms_filled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group keys: ['PubChem_CID', 'TTD_drug_ID', 'BROAD_drug_ID']\n",
      "Fill columns: ['BROAD_drug_ID', 'TTD_drug_ID', 'PubChem_CID']\n",
      "Processing fill column: BROAD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: TTD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: PubChem_CID\n",
      "Processing fill column: PubChem_CID grouped by key: TTD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: TTD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: PubChem_CID\n",
      "Processing fill column: PubChem_CID grouped by key: TTD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: TTD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: PubChem_CID\n",
      "Processing fill column: PubChem_CID grouped by key: TTD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: BROAD_drug_ID\n"
     ]
    }
   ],
   "source": [
    "group_keys = ['PubChem_CID', 'TTD_drug_ID', 'BROAD_drug_ID']  # identifiers to match on\n",
    "fill_columns = ['BROAD_drug_ID', 'TTD_drug_ID', 'PubChem_CID']  # columns to fill\n",
    "\n",
    "print(\"Group keys:\", group_keys)\n",
    "print(\"Fill columns:\", fill_columns)\n",
    "\n",
    "def groupwise_fill(df, group_keys, fill_columns):\n",
    "    df = df.copy()\n",
    "    for col in fill_columns:\n",
    "        for key in group_keys:\n",
    "            print(f\"Processing fill column: {col} grouped by key: {key}\")\n",
    "            # Skip if col == key (makes no sense to fill BROAD_drug_ID by grouping on BROAD_drug_ID)\n",
    "            if col == key:\n",
    "                continue\n",
    "            \n",
    "            # Only operate where group key is not null\n",
    "            valid_rows = df[key].notna()\n",
    "            \n",
    "            # Apply transform only on rows with valid group keys\n",
    "            try:\n",
    "                filled = df.loc[valid_rows].groupby(key, group_keys=False)[col].transform(\n",
    "                    lambda x: x.ffill().bfill() if x.notna().any() else x\n",
    "                )\n",
    "                # Assign the filled values back\n",
    "                df.loc[valid_rows, col] = filled\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to groupby {key} for column {col}: {e}\")\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def iterative_groupwise_fill(df, group_keys, fill_columns, max_iter=5):\n",
    "    df = df.copy()\n",
    "    for _ in range(max_iter):\n",
    "        before_fill = df[fill_columns].isna().sum().sum()\n",
    "        df = groupwise_fill(df, group_keys, fill_columns)\n",
    "        after_fill = df[fill_columns].isna().sum().sum()\n",
    "        if after_fill >= before_fill:\n",
    "            break  # Stop if no more progress\n",
    "    return df\n",
    "\n",
    "# Perform the iterative groupwise fill\n",
    "synonym_df_filled = iterative_groupwise_fill(merged_df, group_keys, fill_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BROAD_drug_ID</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>TTD_drug_ID</th>\n",
       "      <th>PubChem_CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-K52256627</td>\n",
       "      <td>chlorhexidine</td>\n",
       "      <td>D0V4GY</td>\n",
       "      <td>9552079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-K52256627</td>\n",
       "      <td>chlorhexidine, combinations</td>\n",
       "      <td>D0V4GY</td>\n",
       "      <td>9552079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-K52256627</td>\n",
       "      <td>1,1'-hexamethylenebis[5-(4-chlorophenyl)biguan...</td>\n",
       "      <td>D0V4GY</td>\n",
       "      <td>9552079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-K52256627</td>\n",
       "      <td>1n-[6-[4-chloroanilino(imino)methylamino(imino...</td>\n",
       "      <td>D0V4GY</td>\n",
       "      <td>9552079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-K52256627</td>\n",
       "      <td>biguanide derivative</td>\n",
       "      <td>D0V4GY</td>\n",
       "      <td>9552079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435525</th>\n",
       "      <td>BRD-K63068307</td>\n",
       "      <td>2-(difluoromethyl)-1-[4,6-di(4-morpholinyl)-1,...</td>\n",
       "      <td>D0O1LD</td>\n",
       "      <td>11647372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435526</th>\n",
       "      <td>BRD-K63068307</td>\n",
       "      <td>2-(difluoromethyl)-1-[4,6-di(morpholin-4-yl)-1...</td>\n",
       "      <td>D0O1LD</td>\n",
       "      <td>11647372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435527</th>\n",
       "      <td>BRD-K63068307</td>\n",
       "      <td>4,4''-(6-(2-(difluoromethyl)-1h-benzo[d]imidaz...</td>\n",
       "      <td>D0O1LD</td>\n",
       "      <td>11647372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435528</th>\n",
       "      <td>BRD-K63068307</td>\n",
       "      <td>4,4-(6-(2-(difluoromethyl)-1h-benzo[d]imidazol...</td>\n",
       "      <td>D0O1LD</td>\n",
       "      <td>11647372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435529</th>\n",
       "      <td>BRD-K63068307</td>\n",
       "      <td>zs4</td>\n",
       "      <td>D0O1LD</td>\n",
       "      <td>11647372.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435530 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BROAD_drug_ID                                           synonyms  \\\n",
       "0       BRD-K52256627                                      chlorhexidine   \n",
       "1       BRD-K52256627                        chlorhexidine, combinations   \n",
       "2       BRD-K52256627  1,1'-hexamethylenebis[5-(4-chlorophenyl)biguan...   \n",
       "3       BRD-K52256627  1n-[6-[4-chloroanilino(imino)methylamino(imino...   \n",
       "4       BRD-K52256627                               biguanide derivative   \n",
       "...               ...                                                ...   \n",
       "435525  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(4-morpholinyl)-1,...   \n",
       "435526  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(morpholin-4-yl)-1...   \n",
       "435527  BRD-K63068307  4,4''-(6-(2-(difluoromethyl)-1h-benzo[d]imidaz...   \n",
       "435528  BRD-K63068307  4,4-(6-(2-(difluoromethyl)-1h-benzo[d]imidazol...   \n",
       "435529  BRD-K63068307                                                zs4   \n",
       "\n",
       "       TTD_drug_ID  PubChem_CID  \n",
       "0           D0V4GY    9552079.0  \n",
       "1           D0V4GY    9552079.0  \n",
       "2           D0V4GY    9552079.0  \n",
       "3           D0V4GY    9552079.0  \n",
       "4           D0V4GY    9552079.0  \n",
       "...            ...          ...  \n",
       "435525      D0O1LD   11647372.0  \n",
       "435526      D0O1LD   11647372.0  \n",
       "435527      D0O1LD   11647372.0  \n",
       "435528      D0O1LD   11647372.0  \n",
       "435529      D0O1LD   11647372.0  \n",
       "\n",
       "[435530 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fill column: BROAD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: BROAD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: PubChem_CID\n",
      "Processing fill column: TTD_drug_ID grouped by key: TTD_drug_ID\n",
      "Processing fill column: TTD_drug_ID grouped by key: BROAD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: PubChem_CID\n",
      "Processing fill column: PubChem_CID grouped by key: TTD_drug_ID\n",
      "Processing fill column: PubChem_CID grouped by key: BROAD_drug_ID\n"
     ]
    }
   ],
   "source": [
    "synonym_df_filled = iterative_groupwise_fill(synonym_df_filled, group_keys, fill_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#synonym_df_filled = pd.read_csv('../output/merged_200K_drug_synonyms_w_sigmeta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in each column:\n",
      "BROAD_drug_ID    242309\n",
      "synonyms              1\n",
      "TTD_drug_ID       51795\n",
      "PubChem_CID      310169\n",
      "dtype: int64\n",
      "Unique counts in each column:\n",
      "BROAD_drug_ID     33858\n",
      "synonyms         435420\n",
      "TTD_drug_ID       30713\n",
      "PubChem_CID        1351\n",
      "dtype: int64\n",
      "Data types of each column:\n",
      "BROAD_drug_ID     object\n",
      "synonyms          object\n",
      "TTD_drug_ID       object\n",
      "PubChem_CID      float64\n",
      "dtype: object\n",
      "First few rows of the DataFrame:\n",
      "   BROAD_drug_ID                                           synonyms  \\\n",
      "0  BRD-K52256627                                      chlorhexidine   \n",
      "1  BRD-K52256627                        chlorhexidine, combinations   \n",
      "2  BRD-K52256627  1,1'-hexamethylenebis[5-(4-chlorophenyl)biguan...   \n",
      "3  BRD-K52256627  1n-[6-[4-chloroanilino(imino)methylamino(imino...   \n",
      "4  BRD-K52256627                               biguanide derivative   \n",
      "\n",
      "  TTD_drug_ID  PubChem_CID  \n",
      "0      D0V4GY    9552079.0  \n",
      "1      D0V4GY    9552079.0  \n",
      "2      D0V4GY    9552079.0  \n",
      "3      D0V4GY    9552079.0  \n",
      "4      D0V4GY    9552079.0  \n",
      "Last few rows of the DataFrame:\n",
      "        BROAD_drug_ID                                           synonyms  \\\n",
      "435525  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(4-morpholinyl)-1,...   \n",
      "435526  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(morpholin-4-yl)-1...   \n",
      "435527  BRD-K63068307  4,4''-(6-(2-(difluoromethyl)-1h-benzo[d]imidaz...   \n",
      "435528  BRD-K63068307  4,4-(6-(2-(difluoromethyl)-1h-benzo[d]imidazol...   \n",
      "435529  BRD-K63068307                                                zs4   \n",
      "\n",
      "       TTD_drug_ID  PubChem_CID  \n",
      "435525      D0O1LD   11647372.0  \n",
      "435526      D0O1LD   11647372.0  \n",
      "435527      D0O1LD   11647372.0  \n",
      "435528      D0O1LD   11647372.0  \n",
      "435529      D0O1LD   11647372.0  \n",
      "Shape of the DataFrame: (435530, 4)\n",
      "Number of duplicate rows: 0\n",
      "Missing values in each column:\n",
      "BROAD_drug_ID    242309\n",
      "synonyms              1\n",
      "TTD_drug_ID       51795\n",
      "PubChem_CID      310169\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get statistics of synonym_df_filled\n",
    "synonym_df_filled.describe(include='all')\n",
    "# Check for NaN values in the DataFrame\n",
    "nan_counts = synonym_df_filled.isna().sum()\n",
    "print(\"NaN counts in each column:\")\n",
    "print(nan_counts)\n",
    "# Check for unique values in each column\n",
    "unique_counts = synonym_df_filled.nunique()\n",
    "print(\"Unique counts in each column:\")\n",
    "print(unique_counts)\n",
    "# Check the data types of each column\n",
    "data_types = synonym_df_filled.dtypes\n",
    "print(\"Data types of each column:\")\n",
    "print(data_types)\n",
    "# Check the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(synonym_df_filled.head())\n",
    "# Check the last few rows of the DataFrame\n",
    "print(\"Last few rows of the DataFrame:\")\n",
    "print(synonym_df_filled.tail())\n",
    "# Check the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame:\", synonym_df_filled.shape)\n",
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_rows = synonym_df_filled.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows)\n",
    "# Check for missing values in the DataFrame\n",
    "missing_values = synonym_df_filled.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates in synonym_df_filled\n",
    "synonym_df_filled = synonym_df_filled.drop_duplicates()\n",
    "# reset index of synonym_df_filled\n",
    "synonym_df_filled.reset_index(drop=True, inplace=True)\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "#drop na rows synoyms\n",
    "synonym_df_filled = synonym_df_filled.dropna(subset=['synonyms'])\n",
    "synonym_df_filled = synonym_df_filled.dropna(subset=['BROAD_drug_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in each column:\n",
      "BROAD_drug_ID        0\n",
      "synonyms             0\n",
      "TTD_drug_ID      45737\n",
      "PubChem_CID      88237\n",
      "dtype: int64\n",
      "Unique counts in each column:\n",
      "BROAD_drug_ID     33858\n",
      "synonyms         193113\n",
      "TTD_drug_ID        2775\n",
      "PubChem_CID         950\n",
      "dtype: int64\n",
      "Data types of each column:\n",
      "BROAD_drug_ID     object\n",
      "synonyms          object\n",
      "TTD_drug_ID       object\n",
      "PubChem_CID      float64\n",
      "dtype: object\n",
      "First few rows of the DataFrame:\n",
      "   BROAD_drug_ID                                           synonyms  \\\n",
      "0  BRD-K52256627                                      chlorhexidine   \n",
      "1  BRD-K52256627                        chlorhexidine, combinations   \n",
      "2  BRD-K52256627  1,1'-hexamethylenebis[5-(4-chlorophenyl)biguan...   \n",
      "3  BRD-K52256627  1n-[6-[4-chloroanilino(imino)methylamino(imino...   \n",
      "4  BRD-K52256627                               biguanide derivative   \n",
      "\n",
      "  TTD_drug_ID  PubChem_CID  \n",
      "0      D0V4GY    9552079.0  \n",
      "1      D0V4GY    9552079.0  \n",
      "2      D0V4GY    9552079.0  \n",
      "3      D0V4GY    9552079.0  \n",
      "4      D0V4GY    9552079.0  \n",
      "Last few rows of the DataFrame:\n",
      "        BROAD_drug_ID                                           synonyms  \\\n",
      "435525  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(4-morpholinyl)-1,...   \n",
      "435526  BRD-K63068307  2-(difluoromethyl)-1-[4,6-di(morpholin-4-yl)-1...   \n",
      "435527  BRD-K63068307  4,4''-(6-(2-(difluoromethyl)-1h-benzo[d]imidaz...   \n",
      "435528  BRD-K63068307  4,4-(6-(2-(difluoromethyl)-1h-benzo[d]imidazol...   \n",
      "435529  BRD-K63068307                                                zs4   \n",
      "\n",
      "       TTD_drug_ID  PubChem_CID  \n",
      "435525      D0O1LD   11647372.0  \n",
      "435526      D0O1LD   11647372.0  \n",
      "435527      D0O1LD   11647372.0  \n",
      "435528      D0O1LD   11647372.0  \n",
      "435529      D0O1LD   11647372.0  \n",
      "Shape of the DataFrame: (193221, 4)\n",
      "Number of duplicate rows: 0\n",
      "Missing values in each column:\n",
      "BROAD_drug_ID        0\n",
      "synonyms             0\n",
      "TTD_drug_ID      45737\n",
      "PubChem_CID      88237\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get statistics of synonym_df_filled\n",
    "synonym_df_filled.describe(include='all')\n",
    "# Check for NaN values in the DataFrame\n",
    "nan_counts = synonym_df_filled.isna().sum()\n",
    "print(\"NaN counts in each column:\")\n",
    "print(nan_counts)\n",
    "# Check for unique values in each column\n",
    "unique_counts = synonym_df_filled.nunique()\n",
    "print(\"Unique counts in each column:\")\n",
    "print(unique_counts)\n",
    "# Check the data types of each column\n",
    "data_types = synonym_df_filled.dtypes\n",
    "print(\"Data types of each column:\")\n",
    "print(data_types)\n",
    "# Check the first few rows of the DataFrame\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(synonym_df_filled.head())\n",
    "# Check the last few rows of the DataFrame\n",
    "print(\"Last few rows of the DataFrame:\")\n",
    "print(synonym_df_filled.tail())\n",
    "# Check the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame:\", synonym_df_filled.shape)\n",
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_rows = synonym_df_filled.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows)\n",
    "# Check for missing values in the DataFrame\n",
    "missing_values = synonym_df_filled.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_df_filled.to_csv('../output/merged_200K_drug_synonyms.csv', index=False, compression=None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN72wA78p4chrpAoeF/LFO/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
